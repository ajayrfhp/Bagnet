{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretabble image classifier using deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(100, 100, 3)\n",
    "q = 10\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 3, 20, 20])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def img_to_patch(img, patch_size):\n",
    "    num_patches = int(img.shape[1] / patch_size)\n",
    "    img1 = torch.stack(torch.split(img, num_patches, dim=2))\n",
    "    img2 = torch.stack(torch.split(img1, num_patches, dim=2))\n",
    "    return img2\n",
    "    \n",
    "img = torch.randn(3, 200, 200)\n",
    "img_to_patch(img, 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 10, 3, 20, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'asd'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AdhocNet(nn.Module):\n",
    "    def img_to_patch(self, img, patch_size):\n",
    "        '''\n",
    "        Args\n",
    "            img - (3, W, H)\n",
    "            patch_size - (Q)\n",
    "        Returns\n",
    "            Patches (W/Q, H/Q, 3, Q, Q)\n",
    "        '''\n",
    "        num_patches = int(img.shape[1] / patch_size)\n",
    "        img1 = torch.stack(torch.split(img, num_patches, dim=2))\n",
    "        img2 = torch.stack(torch.split(img1, num_patches, dim=2))\n",
    "        return img2\n",
    "    \n",
    "    def patch_to_representation(self, patch):\n",
    "        '''\n",
    "        Args\n",
    "            Patch - (3, Q, Q)\n",
    "        Returns\n",
    "            Representation - (V)\n",
    "        '''\n",
    "        \n",
    "    def patches_to_representations(self, patches):\n",
    "        '''\n",
    "        Args\n",
    "            patches - (W/Q, H/Q, 3, Q, Q)\n",
    "        Returns\n",
    "            representations - (W/Q, H/Q, V)\n",
    "        '''\n",
    "        representations = []\n",
    "        for i in range(patches.shape[0]):\n",
    "            row = [self.patch_to_representation(patches[i,j]) for j in range(patches.shape[1])]\n",
    "            representations.append(torch) \n",
    "        \n",
    "\n",
    "    def __init__(self, patch_size):\n",
    "        super(AdhocNet, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "    def forward(self, x):\n",
    "        patches = torch.stack([self.img_to_patch(img, self.patch_size) for img in x])\n",
    "        representations = torch.stack([ self.patches_to_representations(patch) for patch in patches])\n",
    "        return x\n",
    "        \n",
    "\n",
    "model = AdhocNet(10)\n",
    "model(torch.randn(1, 3, 200, 200))\n",
    "'asd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 222, 222]           1,792\n",
      "            Conv2d-2         [-1, 64, 111, 111]           4,160\n",
      "            Conv2d-3         [-1, 64, 109, 109]          36,928\n",
      "            Conv2d-4         [-1, 64, 109, 109]           4,160\n",
      "            Conv2d-5         [-1, 64, 109, 109]           4,160\n",
      "            Conv2d-6         [-1, 64, 109, 109]           4,160\n",
      "            Conv2d-7         [-1, 64, 109, 109]           4,160\n",
      "            Conv2d-8         [-1, 64, 109, 109]           4,160\n",
      "            Conv2d-9         [-1, 64, 109, 109]           4,160\n",
      "           Conv2d-10         [-1, 64, 109, 109]           4,160\n",
      "           Conv2d-11          [-1, 128, 55, 55]           8,320\n",
      "           Conv2d-12          [-1, 128, 53, 53]         147,584\n",
      "           Conv2d-13          [-1, 128, 53, 53]          16,512\n",
      "           Conv2d-14          [-1, 128, 53, 53]          16,512\n",
      "           Conv2d-15          [-1, 128, 53, 53]          16,512\n",
      "           Conv2d-16          [-1, 128, 53, 53]          16,512\n",
      "           Conv2d-17          [-1, 128, 53, 53]          16,512\n",
      "           Conv2d-18          [-1, 128, 53, 53]          16,512\n",
      "           Conv2d-19          [-1, 128, 53, 53]          16,512\n",
      "           Conv2d-20          [-1, 256, 27, 27]          33,024\n",
      "           Conv2d-21          [-1, 256, 27, 27]          65,792\n",
      "           Conv2d-22          [-1, 256, 27, 27]          65,792\n",
      "           Conv2d-23          [-1, 256, 27, 27]          65,792\n",
      "           Conv2d-24          [-1, 256, 27, 27]          65,792\n",
      "           Conv2d-25          [-1, 256, 27, 27]          65,792\n",
      "           Conv2d-26          [-1, 256, 27, 27]          65,792\n",
      "           Conv2d-27          [-1, 256, 27, 27]          65,792\n",
      "           Conv2d-28          [-1, 256, 27, 27]          65,792\n",
      "           Conv2d-29          [-1, 512, 14, 14]         131,584\n",
      "           Conv2d-30          [-1, 512, 14, 14]         262,656\n",
      "           Conv2d-31          [-1, 512, 14, 14]         262,656\n",
      "           Conv2d-32          [-1, 512, 14, 14]         262,656\n",
      "           Conv2d-33          [-1, 512, 14, 14]         262,656\n",
      "           Conv2d-34          [-1, 512, 14, 14]         262,656\n",
      "           Conv2d-35          [-1, 512, 14, 14]         262,656\n",
      "           Conv2d-36          [-1, 512, 14, 14]         262,656\n",
      "           Conv2d-37          [-1, 512, 14, 14]         262,656\n",
      "           Linear-38                 [-1, 1000]     100,353,000\n",
      "================================================================\n",
      "Total params: 103,488,680\n",
      "Trainable params: 103,488,680\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 121.10\n",
      "Params size (MB): 394.78\n",
      "Estimated Total Size (MB): 516.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class BagNet9(nn.Module):\n",
    "    def get_resblock(self, conv_parameters):\n",
    "        res_layers = [ nn.Conv2d(*conv_param) for conv_param in conv_parameters]\n",
    "        res_block = nn.Sequential(*res_layers)\n",
    "        return res_block\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(BagNet9, self).__init__()\n",
    "        self.c1 = nn.Conv2d(3, 64, 3)\n",
    "        \n",
    "        self.res1 = self.get_resblock([(64, 64, 1, 2), (64, 64, 3), (64, 64, 1)])\n",
    "        self.res2 = self.get_resblock([(64, 64, 1), (64, 64, 1), (64, 64, 1)])\n",
    "        self.res3 = self.get_resblock([(64, 64, 1), (64, 64, 1), (64, 64, 1)])\n",
    "        \n",
    "        self.res4 = self.get_resblock([(64, 128, 1, 2), (128, 128, 3), (128, 128, 1)])\n",
    "        self.res5 = self.get_resblock([(128, 128, 1), (128, 128, 1), (128, 128, 1)])\n",
    "        self.res6 = self.get_resblock([(128, 128, 1), (128, 128, 1), (128, 128, 1)])\n",
    "        \n",
    "        self.res7 = self.get_resblock([(128, 256, 1, 2), (256, 256, 1), (256, 256, 1)])\n",
    "        self.res8 = self.get_resblock([(256, 256, 1), (256, 256, 1), (256, 256, 1)])\n",
    "        self.res9 = self.get_resblock([(256, 256, 1), (256, 256, 1), (256, 256, 1)])\n",
    "        \n",
    "        self.res10 = self.get_resblock([(256, 512, 1, 2), (512, 512, 1), (512, 512, 1)])\n",
    "        self.res11 = self.get_resblock([(512, 512, 1), (512, 512, 1), (512, 512, 1)])\n",
    "        self.res12 = self.get_resblock([(512, 512, 1), (512, 512, 1), (512, 512, 1)])\n",
    "        self.fc1 = nn.Linear(512 * 14 * 14, 1000)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = self.c1(x)\n",
    "        h2 = self.res1(h1)\n",
    "        h3 = self.res2(h2)\n",
    "        h4 = self.res3(h3)\n",
    "        \n",
    "        h5 = self.res4(h4)\n",
    "        h6 = self.res5(h5)\n",
    "        h7 = self.res6(h6)\n",
    "        \n",
    "        h8 = self.res7(h7)\n",
    "        h9 = self.res8(h8)\n",
    "        h10 = self.res9(h9)\n",
    "        \n",
    "        h11 = self.res10(h10)\n",
    "        h12 = self.res11(h11)\n",
    "        h13 = self.res12(h12)\n",
    "        predictions = self.fc1(h13.view(-1, 512 * 14 * 14))\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "model = BagNet9()\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
